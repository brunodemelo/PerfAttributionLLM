{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1772c485-df33-4e4d-8c71-da6596a168fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences for Defensive_1_31_2022_to_3_31_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Defensive_1_31_2022_to_3_31_2022.csv\n",
      "Sentences for Defensive_4_1_2022_to_6_30_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Defensive_4_1_2022_to_6_30_2022.csv\n",
      "Sentences for Defensive_7_1_2022_to_9_30_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Defensive_7_1_2022_to_9_30_2022.csv\n",
      "Sentences for Defensive_10_1_2022_to_12_31_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Defensive_10_1_2022_to_12_31_2022.csv\n",
      "Sentences for Growth_1_31_2022_to_3_31_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Growth_1_31_2022_to_3_31_2022.csv\n",
      "Sentences for Growth_4_1_2022_to_6_30_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Growth_4_1_2022_to_6_30_2022.csv\n",
      "Sentences for Growth_7_1_2022_to_9_30_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Growth_7_1_2022_to_9_30_2022.csv\n",
      "Sentences for Growth_10_1_2022_to_12_31_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Growth_10_1_2022_to_12_31_2022.csv\n",
      "Sentences for Balanced_1_31_2022_to_3_31_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Balanced_1_31_2022_to_3_31_2022.csv\n",
      "Sentences for Balanced_4_1_2022_to_6_30_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Balanced_4_1_2022_to_6_30_2022.csv\n",
      "Sentences for Balanced_7_1_2022_to_9_30_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Balanced_7_1_2022_to_9_30_2022.csv\n",
      "Sentences for Balanced_10_1_2022_to_12_31_2022 have been generated and saved to ./Data/Attribution/sentences_summary_new_Balanced_10_1_2022_to_12_31_2022.csv\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of Objective 1\n",
    "#bullet points\n",
    "\n",
    "#Step 1\n",
    "#Create synthetic sentences\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './Data/Attribution/attribution_by_gics_Obj1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define a function to create sentences based on the values\n",
    "def create_sentences(row, benchmark_total_return):\n",
    "    sector = row['GICS Sector']\n",
    "    portfolio_weight = row['Portfolio Weight']\n",
    "    benchmark_weight = row['Benchmark Weight']\n",
    "    portfolio_return = row['Portfolio Return']\n",
    "    benchmark_return = row['Benchmark Return']\n",
    "    allocation_effect = row['Allocation Effect']\n",
    "    selection_effect = row['Selection Effect']\n",
    "    benchmark_total_return = benchmark_total_return\n",
    "\n",
    "    # Determine the weight status\n",
    "    weight_status = 'overweight' if portfolio_weight > benchmark_weight else 'underweight'\n",
    "\n",
    "    # Determine the market performance\n",
    "    market_performance = 'outperformed' if benchmark_return > benchmark_total_return else 'underperformed'\n",
    "    \n",
    "    # Determine portfolio performance vs benchmar\n",
    "    sector_performance = 'outperformed' if portfolio_return > benchmark_return else 'underperformed'\n",
    "\n",
    "    # Allocation sentence\n",
    "    allocation_sentence = (\n",
    "        f\"The {sector} sector had a {'positive' if allocation_effect > 0 else 'negative'} allocation effect of {allocation_effect}. \"\n",
    "        f\"This was due to the fund being {weight_status} compared to benchmark in a sector that {market_performance} the benchmark total return.\"\n",
    "        #f\"{weight_status.capitalize()} position {market_performance} the market.\"\n",
    "    )\n",
    "\n",
    "    # Selection sentence\n",
    "    selection_sentence = (\n",
    "        f\"The {sector} sector had a {'positive' if selection_effect > 0 else 'negative'} selection effect of {selection_effect}. \"\n",
    "        f\"Fund investments {sector_performance} compared to the sector benchmark.\"\n",
    "    )\n",
    "\n",
    "    return allocation_sentence, selection_sentence\n",
    "\n",
    "# Process each block of 12 rows and create a separate CSV file\n",
    "for start_row in range(0, df.shape[0], 12):\n",
    "    block_df = df.iloc[start_row:start_row + 12]\n",
    "    \n",
    "    #Calculate the total benchmark return for the block\n",
    "    benchmark_total_return = (block_df['Benchmark Weight'] * block_df['Benchmark Return']).sum()\n",
    "    sentences = block_df.apply(lambda row: create_sentences(row, benchmark_total_return), axis=1)\n",
    "    #sentences = block_df.apply(create_sentences, axis=1)\n",
    "    sentences_df = pd.DataFrame(list(sentences), columns=['Allocation', 'Selection'])\n",
    "\n",
    "    # Add 'Fund' and 'Period' from the original DataFrame to the sentences DataFrame\n",
    "    # Reset the index of block_df to ensure alignment\n",
    "    block_df = block_df.reset_index(drop=True)\n",
    "    sentences_df['Fund'] = block_df.loc[0, 'Fund']  # Take the first 'Fund' value from the block\n",
    "    sentences_df['Period'] = block_df.loc[0, 'Period']  # Take the first 'Period' value from the block\n",
    "    \n",
    "    # Construct the file name\n",
    "    fund_period_str = block_df.iloc[0]['Fund'] + '_' + block_df.iloc[0]['Period'].replace(' ', '_').replace('/', '_')\n",
    "    file_name = f'sentences_summary_new_{fund_period_str}.csv'\n",
    "\n",
    "    # Save the sentences to a new CSV file\n",
    "    output_file_path = f'./Data/Attribution/{file_name}'\n",
    "    sentences_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    print(f\"Sentences for {fund_period_str} have been generated and saved to\", output_file_path)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81a52e1f-fe56-4ede-a4b8-c62ad858491f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: output_bullet_zero_2_Growth_4_1_2022 to 6_30_2022_2023-11-05_18-47.csv\n",
      "Processing file: output_bullet_zero_2_Defensive_7_1_2022 to 9_30_2022_2023-11-05_19-42.csv\n",
      "Processing file: output_bullet_zero_2_Balanced_4_1_2022 to 6_30_2022_2023-11-05_19-05.csv\n",
      "Processing file: output_bullet_zero_2_Defensive_4_1_2022 to 6_30_2022_2023-11-05_19-40.csv\n",
      "Processing file: output_bullet_zero_2_Balanced_1_31_2022 to 3_31_2022_2023-11-05_19-00.csv\n",
      "Processing file: output_bullet_zero_2_Growth_1_31_2022 to 3_31_2022_2023-11-05_18-42.csv\n",
      "Processing file: output_bullet_zero_2_Balanced_10_1_2022 to 12_31_2022_2023-11-05_19-03.csv\n",
      "Processing file: output_bullet_zero_2_Defensive_1_31_2022 to 3_31_2022_2023-11-05_19-34.csv\n",
      "Processing file: output_bullet_zero_2_Growth_7_1_2022 to 9_30_2022_2023-11-05_18-50.csv\n",
      "Processing file: output_bullet_zero_2_Defensive_10_1_2022 to 12_31_2022_2023-11-05_19-37.csv\n",
      "Processing file: output_bullet_zero_2_Balanced_7_1_2022 to 9_30_2022_2023-11-05_19-08.csv\n",
      "Processing file: output_bullet_zero_2_Growth_10_1_2022 to 12_31_2022_2023-11-05_18-45.csv\n",
      "Similarity results saved.\n"
     ]
    }
   ],
   "source": [
    "# compare synthetic with bullet points\n",
    "# calculates similarities using GPT and ST\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "openai.api_key = \"\"\n",
    "\n",
    "# File path for the similarity scores CSV\n",
    "similarity_scores_file = './Data/Attribution/Eval_Obj_1/similarity_scores_new_ppts_update_zero.csv'\n",
    "\n",
    "# Check if the file exists and delete its contents\n",
    "if os.path.exists(similarity_scores_file):\n",
    "    open(similarity_scores_file, 'w').close()\n",
    "\n",
    "def extract_period(filename):\n",
    "    # Split the filename into parts\n",
    "    file_parts = filename.split('_')\n",
    "\n",
    "    # The period starts from the sixth part and ends at the second last part\n",
    "    #period_parts = file_parts[6:-2]\n",
    "    period_parts = file_parts[5:-2] #for zero shot prompt\n",
    "    # Join the period parts and replace spaces with underscores\n",
    "    return '_'.join(period_parts).replace(' ', '_')   \n",
    "\n",
    "# Function to extract the prefix type from the filename\n",
    "def extract_prefix_type(filename, prefix):\n",
    "    return prefix.split('_')[2] + '_' + prefix.split('_')[3]\n",
    "\n",
    "#def extract_sector_from_sentence(sentence):\n",
    "#    start = sentence.index(\"for sector \") + len(\"for sector \")\n",
    "#    end = sentence.index(\" \", start)\n",
    "#    return sentence[start:end]\n",
    "\n",
    "def extract_sector_from_sentence(sentence):\n",
    "    # List of words that might follow a sector name\n",
    "    following_words = [\"is\", \"had\", \"was\", \"sector\", \"with\", \"in\", \"and\"]\n",
    "    \n",
    "    # Find the start index of the sector name\n",
    "    start = sentence.index(\"The \") + len(\"sector had \")\n",
    "    \n",
    "    # Split the sentence into words from the start index\n",
    "    words = sentence[start:].split()\n",
    "\n",
    "    # Extract words until we hit a following word or end of the list\n",
    "    sector_name = []\n",
    "    for word in words:\n",
    "        if word in following_words:\n",
    "            break\n",
    "        sector_name.append(word)\n",
    "    \n",
    "    # Join the words to form the sector name and return it\n",
    "    return \" \".join(sector_name)\n",
    "\n",
    "\n",
    "\n",
    "# Define your directory and file prefixes\n",
    "directory = './Data/Attribution/Eval_Obj_1'\n",
    "#prefixes = [\"output_bullet_few_1_new_\", \"output_bullet_few_2_new_\", \"output_bullet_few_3_new_\"]\n",
    "prefixes = [\"output_bullet_zero_2_\"]\n",
    "#prefixes = [\"output_bullet_few_1_new_\"]\n",
    "fund_types = ['Defensive', 'Growth', 'Balanced']\n",
    "\n",
    "# Function to get embeddings using OpenAI's API\n",
    "def get_embeddings(text):\n",
    "    response = openai.Embedding.create(input=[text], engine=\"text-embedding-ada-002\")\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "#ST model\n",
    "model = SentenceTransformer('all-mpnet-base-v2') \n",
    "#sentence-transformers/all-mpnet-base-v2\n",
    "\n",
    "#def calculate_similarity(sentence1, sentence2, model):\n",
    "#    embeds1 = model.encode(sentence1) / np.linalg.norm(model.encode(sentence1), axis=-1, keepdims=True)\n",
    "#    embeds2 = model.encode(sentence2) / np.linalg.norm(model.encode(sentence2), axis=-1, keepdims=True)\n",
    "#    return np.dot(embeds1, embeds2.T)\n",
    "\n",
    "def calculate_similarity(embedding1, embedding2):\n",
    "    return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "\n",
    "similarity_results = []\n",
    "\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    for prefix in prefixes:\n",
    "        for fund in fund_types:\n",
    "            if filename.startswith(prefix + fund):\n",
    "                print(f\"Processing file: {filename}\")\n",
    "                period = extract_period(filename)\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                df = pd.read_csv(file_path)\n",
    "                prefix_type = extract_prefix_type(filename, prefix)\n",
    "\n",
    "                # Iterate over each row of the DataFrame\n",
    "                for idx, row in df.iterrows():\n",
    "                    sentence_1_col1 = row['Allocation']\n",
    "                    sentence_1_col2 = row['Selection']\n",
    "                    \n",
    "                    \n",
    "                    # Assuming there is a corresponding ground truth file with the same row order\n",
    "                    ground_truth_file = os.path.join(directory, f\"sentences_summary_new_{fund}_{period}.csv\")\n",
    "                    if os.path.exists(ground_truth_file):\n",
    "                        ground_truth_df = pd.read_csv(ground_truth_file)\n",
    "                        sentence_2_col1 = ground_truth_df.iloc[idx]['Allocation']\n",
    "                        sentence_2_col2 = ground_truth_df.iloc[idx]['Selection']\n",
    "                    \n",
    "                        # Extract sector from the sentence\n",
    "                        sector = extract_sector_from_sentence(sentence_2_col1)                        \n",
    "                      \n",
    "                        # Calculate similarities using SentenceTransformer\n",
    "                        #similarity_col1 = calculate_similarity(sentence_1_col1, sentence_2_col1, encoder)\n",
    "                        #similarity_col2 = calculate_similarity(sentence_1_col2, sentence_2_col2, encoder)\n",
    "                        # Calculate similarities using SentenceTransformer\n",
    "                        embeddings1 = model.encode([sentence_1_col1, sentence_1_col2])\n",
    "                        embeddings2 = model.encode([sentence_2_col1, sentence_2_col2])\n",
    "                        similarity_st_col1 = calculate_similarity(embeddings1[0], embeddings2[0])\n",
    "                        similarity_st_col2 = calculate_similarity(embeddings1[1], embeddings2[1])\n",
    "                        #embeddings_generated_st.extend([embeddings1[0], embeddings1[1]])\n",
    "                        #embeddings_ground_truth_st.extend([embeddings2[0], embeddings2[1]])\n",
    "                        \n",
    "                        \n",
    "                        # Calculate similarities using OpenAI's GPT-3\n",
    "                        embedding_1_col1 = get_embeddings(sentence_1_col1)\n",
    "                        embedding_2_col1 = get_embeddings(sentence_2_col1)\n",
    "                        similarity_gpt3_col1 = calculate_similarity(embedding_1_col1, embedding_2_col1)\n",
    "\n",
    "                        embedding_1_col2 = get_embeddings(sentence_1_col2)\n",
    "                        embedding_2_col2 = get_embeddings(sentence_2_col2)\n",
    "                        similarity_gpt3_col2 = calculate_similarity(embedding_1_col2, embedding_2_col2)\n",
    "                        #embeddings_generated_gpt3.extend([embedding_1_col1, embedding_1_col2])\n",
    "                        #embeddings_ground_truth_gpt3.extend([embedding_2_col1, embedding_2_col2])\n",
    "                        \n",
    "                        # Calculate similarity\n",
    "                        #similarity_col1 = calculate_similarity(sentence_1_col1, sentence_2_col1, encoder)\n",
    "                        #similarity_col2 = calculate_similarity(sentence_1_col2, sentence_2_col2, encoder)\n",
    "                        #print(f\"Scoring sector: {sector}\")\n",
    "                        # Append the similarity results along with the additional information\n",
    "                        similarity_results.append({\n",
    "                            'File Name': filename,\n",
    "                            'Fund': fund,\n",
    "                            'Period': period,\n",
    "                            'Prefix Type': prefix_type,\n",
    "                            'Sector': sector,\n",
    "                            'Similarity_Allocation': similarity_st_col1,\n",
    "                            'Similarity_Selection': similarity_st_col2,\n",
    "                            \n",
    "                            'GPT3_Similarity_Allocation': similarity_gpt3_col1,\n",
    "                            'GPT3_Similarity_Selection': similarity_gpt3_col2\n",
    "                        })\n",
    "\n",
    "                    \n",
    "                        \n",
    "                        \n",
    "# Convert the results to a DataFrame and save to a CSV file\n",
    "similarity_results_df = pd.DataFrame(similarity_results)\n",
    "\n",
    "similarity_results_df.to_csv(os.path.join(directory, 'similarity_scores_new_ppts_update_zero.csv'), index=False)\n",
    "print(\"Similarity results saved.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4790e20-55ad-4889-923d-43788e28a655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: output_bullet_few_1_new_Balanced_10_1_2022 to 12_31_2022_2023-11-18_14-33.csv\n",
      "Processing file: output_bullet_few_1_new_Balanced_7_1_2022 to 9_30_2022_2023-11-18_14-40.csv\n",
      "Processing file: output_bullet_few_3_new_Growth_1_31_2022 to 3_31_2022_2023-11-16_01-44.csv\n",
      "Processing file: output_bullet_few_3_new_Balanced_10_1_2022 to 12_31_2022_2023-11-16_01-16.csv\n",
      "Processing file: output_bullet_few_3_new_Defensive_10_1_2022 to 12_31_2022_2023-11-16_01-32.csv\n",
      "Processing file: output_bullet_few_1_new_Balanced_4_1_2022 to 6_30_2022_2023-11-18_14-37.csv\n",
      "Processing file: output_bullet_few_2_new_Balanced_4_1_2022 to 6_30_2022_2023-11-16_02-09.csv\n",
      "Processing file: output_bullet_few_3_new_Defensive_4_1_2022 to 6_30_2022_2023-11-16_01-37.csv\n",
      "Processing file: output_bullet_few_2_new_Balanced_7_1_2022 to 9_30_2022_2023-11-16_02-12.csv\n",
      "Processing file: output_bullet_few_2_new_Growth_7_1_2022 to 9_30_2022_2023-11-16_02-44.csv\n",
      "Processing file: output_bullet_few_1_new_Growth_4_1_2022 to 6_30_2022_2023-11-18_15-03.csv\n",
      "Processing file: output_bullet_few_2_new_Growth_4_1_2022 to 6_30_2022_2023-11-16_02-39.csv\n",
      "Processing file: output_bullet_few_3_new_Growth_10_1_2022 to 12_31_2022_2023-11-16_01-47.csv\n",
      "Processing file: output_bullet_few_1_new_Defensive_1_31_2022 to 3_31_2022_2023-11-18_14-44.csv\n",
      "Processing file: output_bullet_few_1_new_Growth_7_1_2022 to 9_30_2022_2023-11-18_15-17.csv\n",
      "Processing file: output_bullet_few_2_new_Balanced_1_31_2022 to 3_31_2022_2023-11-16_02-01.csv\n",
      "Processing file: output_bullet_few_3_new_Balanced_7_1_2022 to 9_30_2022_2023-11-16_01-24.csv\n",
      "Processing file: output_bullet_few_1_new_Defensive_4_1_2022 to 6_30_2022_2023-11-18_14-50.csv\n",
      "Processing file: output_bullet_few_2_new_Balanced_10_1_2022 to 12_31_2022_2023-11-16_02-05.csv\n",
      "Processing file: output_bullet_few_2_new_Defensive_1_31_2022 to 3_31_2022_2023-11-16_02-16.csv\n",
      "Processing file: output_bullet_few_2_new_Growth_1_31_2022 to 3_31_2022_2023-11-16_02-31.csv\n",
      "Processing file: output_bullet_few_2_new_Growth_10_1_2022 to 12_31_2022_2023-11-16_02-35.csv\n",
      "Processing file: output_bullet_few_3_new_Balanced_4_1_2022 to 6_30_2022_2023-11-16_01-20.csv\n",
      "Processing file: output_bullet_few_3_new_Defensive_1_31_2022 to 3_31_2022_2023-11-16_01-28.csv\n",
      "Processing file: output_bullet_few_2_new_Defensive_4_1_2022 to 6_30_2022_2023-11-16_02-24.csv\n",
      "Processing file: output_bullet_few_1_new_Growth_1_31_2022 to 3_31_2022_2023-11-18_14-57.csv\n",
      "Processing file: output_bullet_few_3_new_Balanced_1_31_2022 to 3_31_2022_2023-11-16_01-12.csv\n",
      "Processing file: output_bullet_few_1_new_Growth_10_1_2022 to 12_31_2022_2023-11-18_15-00.csv\n",
      "Processing file: output_bullet_few_3_new_Defensive_7_1_2022 to 9_30_2022_2023-11-16_01-40.csv\n",
      "Processing file: output_bullet_few_1_new_Defensive_10_1_2022 to 12_31_2022_2023-11-18_14-47.csv\n",
      "Processing file: output_bullet_few_3_new_Growth_4_1_2022 to 6_30_2022_2023-11-16_01-51.csv\n",
      "Processing file: output_bullet_few_1_new_Defensive_7_1_2022 to 9_30_2022_2023-11-18_14-53.csv\n",
      "Processing file: output_bullet_few_1_new_Balanced_1_31_2022 to 3_31_2022_2023-11-18_14-30.csv\n",
      "Processing file: output_bullet_few_2_new_Defensive_10_1_2022 to 12_31_2022_2023-11-16_02-20.csv\n",
      "Processing file: output_bullet_few_2_new_Defensive_7_1_2022 to 9_30_2022_2023-11-16_02-28.csv\n",
      "Processing file: output_bullet_few_3_new_Growth_7_1_2022 to 9_30_2022_2023-11-16_01-55.csv\n",
      "Results saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "# compare synthetic with bullet points\n",
    "# calculates similarities using ROUGE \n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#openai.api_key = \"\"\n",
    "\n",
    "# Initialize the ROUGE scorer\n",
    "#scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Function to compute ROUGE scores\n",
    "def compute_rouge_scores(summary_text, reference_text):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference_text, summary_text)\n",
    "    return {key: scores[key].fmeasure for key in scores}\n",
    "\n",
    "# File path for the similarity scores CSV\n",
    "rouge_scores_file = './Data/Attribution/Eval_Obj_1/rouge_scores.csv'\n",
    "\n",
    "# Check if the file exists and delete its contents\n",
    "if os.path.exists(similarity_scores_file):\n",
    "    open(similarity_scores_file, 'w').close()\n",
    "\n",
    "def extract_period(filename):\n",
    "    # Split the filename into parts\n",
    "    file_parts = filename.split('_')\n",
    "\n",
    "    # The period starts from the sixth part and ends at the second last part\n",
    "    period_parts = file_parts[6:-2]\n",
    "\n",
    "    # Join the period parts and replace spaces with underscores\n",
    "    return '_'.join(period_parts).replace(' ', '_')   \n",
    "\n",
    "# Function to extract the prefix type from the filename\n",
    "def extract_prefix_type(filename, prefix):\n",
    "    return prefix.split('_')[2] + '_' + prefix.split('_')[3]\n",
    "\n",
    "#def extract_sector_from_sentence(sentence):\n",
    "#    start = sentence.index(\"for sector \") + len(\"for sector \")\n",
    "#    end = sentence.index(\" \", start)\n",
    "#    return sentence[start:end]\n",
    "\n",
    "def extract_sector_from_sentence(sentence):\n",
    "    # List of words that might follow a sector name\n",
    "    following_words = [\"is\", \"had\", \"was\", \"sector\", \"with\", \"in\", \"and\"]\n",
    "    \n",
    "    # Find the start index of the sector name\n",
    "    start = sentence.index(\"The \") + len(\"sector had \")\n",
    "    \n",
    "    # Split the sentence into words from the start index\n",
    "    words = sentence[start:].split()\n",
    "\n",
    "    # Extract words until we hit a following word or end of the list\n",
    "    sector_name = []\n",
    "    for word in words:\n",
    "        if word in following_words:\n",
    "            break\n",
    "        sector_name.append(word)\n",
    "    \n",
    "    # Join the words to form the sector name and return it\n",
    "    return \" \".join(sector_name)\n",
    "\n",
    "\n",
    "# Define your directory and file prefixes\n",
    "directory = './Data/Attribution/Eval_Obj_1'\n",
    "prefixes = [\"output_bullet_few_1_new_\", \"output_bullet_few_2_new_\", \"output_bullet_few_3_new_\"]\n",
    "#prefixes = [\"output_bullet_zero_2_\"]\n",
    "#prefixes = [\"output_bullet_few_1_new_\"]\n",
    "fund_types = ['Defensive', 'Growth', 'Balanced']\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    for prefix in prefixes:\n",
    "        for fund in fund_types:\n",
    "            if filename.startswith(prefix + fund):\n",
    "                print(f\"Processing file: {filename}\")\n",
    "                \n",
    "                period = extract_period(filename)\n",
    "                \n",
    "                file_path = os.path.join(directory, filename)\n",
    "                \n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                prefix_type = extract_prefix_type(filename, prefix)\n",
    "\n",
    "                # Iterate over each row of the DataFrame\n",
    "                for idx, row in df.iterrows():\n",
    "                    sentence_1_col1 = row['Allocation']\n",
    "                    sentence_1_col2 = row['Selection']\n",
    "                    \n",
    "                    # Extract sector from the sentence\n",
    "                    sector = extract_sector_from_sentence(sentence_2_col1)                        \n",
    "\n",
    "                    # Assuming there is a corresponding ground truth file with the same row order\n",
    "                    ground_truth_file = os.path.join(directory, f\"sentences_summary_new_{fund}_{period}.csv\")\n",
    "                    \n",
    "                    ground_truth_df = pd.read_csv(ground_truth_file)\n",
    "                    sentence_2_col1 = ground_truth_df.iloc[idx]['Allocation']\n",
    "                    sentence_2_col2 = ground_truth_df.iloc[idx]['Selection']\n",
    "                    \n",
    "                    # Compute ROUGE scores for Allocation\n",
    "                    rouge_scores_allocation = compute_rouge_scores(sentence_1_col1, sentence_2_col1)\n",
    "\n",
    "                    # Compute ROUGE scores for Selection\n",
    "                    rouge_scores_selection = compute_rouge_scores(sentence_1_col2, sentence_2_col2)\n",
    "\n",
    "                    # Append results\n",
    "                    results.append({\n",
    "                        'File Name': filename,\n",
    "                        'Fund': fund,\n",
    "                        'Period': period,\n",
    "                        'Prefix Type': prefix_type,\n",
    "                        'Sector': sector,\n",
    "                        'ROUGE-1 Allocation F-measure': rouge_scores_allocation['rouge1'],\n",
    "                        'ROUGE-2 Allocation F-measure': rouge_scores_allocation['rouge2'],\n",
    "                        'ROUGE-L Allocation F-measure': rouge_scores_allocation['rougeL'],\n",
    "                        'ROUGE-1 Selection F-measure': rouge_scores_selection['rouge1'],\n",
    "                        'ROUGE-2 Selection F-measure': rouge_scores_selection['rouge2'],\n",
    "                        'ROUGE-L Selection F-measure': rouge_scores_selection['rougeL']\n",
    "                    })\n",
    "\n",
    "                    \n",
    "                        \n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(\"./Data/Attribution/Eval_Obj_1/rouge_scores.csv\", index=False)\n",
    "\n",
    "print(\"Results saved to CSV.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc9c2476-0afa-4f2e-b4e1-f49c2d3011d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary CSV saved at: ./Data/Attribution/Eval_Obj_1/summary_csv_points_by_effect_type_few_new.csv\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of Objective 1\n",
    "# CSV tables\n",
    "# this one works#\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory where your files are located\n",
    "directory = \"./Data/Attribution/Eval_Obj_1\"\n",
    "\n",
    "# List of prefixes to filter files\n",
    "prefixes = [\"output_csv_zero_2_\", \"output_csv_few_1_new_\", \"output_csv_few_2_new_\", \"output_csv_few_3_new_\"]\n",
    "\n",
    "# Function to extract the prefix type from the filename\n",
    "def extract_prefix_type(filename, prefixes):\n",
    "    for prefix in prefixes:\n",
    "        if filename.startswith(prefix):\n",
    "            parts = prefix.split('_')\n",
    "            return '_'.join(parts[2:4])\n",
    "    return 'Unknown'\n",
    "\n",
    "# Initialize a list to store the summary of each file\n",
    "summary = []\n",
    "\n",
    "# Function to compare floating-point values with a tolerance\n",
    "def is_close(a, b, tol=1e-6):\n",
    "    try:\n",
    "        return abs(float(a) - float(b)) < tol\n",
    "    except ValueError:\n",
    "        # Return False if conversion to float fails\n",
    "        return False\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file starts with any of the prefixes\n",
    "    if any(filename.startswith(prefix) for prefix in prefixes) and filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Initialize total points for each comparison category, separated by effect type\n",
    "        total_points_value_allocation = 0\n",
    "        total_points_value_selection = 0\n",
    "        total_points_sector_weight_allocation = 0\n",
    "        total_points_sector_weight_selection = 0\n",
    "        total_points_sector_performance_allocation = 0\n",
    "        total_points_sector_performance_selection = 0\n",
    "\n",
    "        # Initialize counters for maximum points\n",
    "        max_points_value_allocation = 0\n",
    "        max_points_value_selection = 0\n",
    "        max_points_sector_weight_allocation = 0\n",
    "        max_points_sector_weight_selection = 0\n",
    "        max_points_sector_performance_allocation = 0\n",
    "        max_points_sector_performance_selection = 0\n",
    "        \n",
    "        # Extract the prefix type from the filename\n",
    "        prefix_type = extract_prefix_type(filename, prefixes)\n",
    "\n",
    "        # Loop through each row of the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            effect_type = row['Effect Type']\n",
    "            if effect_type == 'Allocation':\n",
    "                # Increment maximum points counters for Allocation\n",
    "                max_points_value_allocation += 1\n",
    "                if 'Sector Weight' in row and 'True Sector Weight' in row:\n",
    "                    max_points_sector_weight_allocation += 1\n",
    "                if 'Sector Performance' in row and 'True Performance' in row:\n",
    "                    max_points_sector_performance_allocation += 1\n",
    "            \n",
    "            #effect_type = row['Effect Type']\n",
    "            # Check if the current row is for Allocation or Selection\n",
    "            #if effect_type == 'Allocation':\n",
    "                if not pd.isna(row['Value']) and not pd.isna(row['True Value']) and is_close(row['Value'], row['True Value']):\n",
    "                    total_points_value_allocation += 1\n",
    "                if 'Sector Weight' in row and 'True Sector Weight' in row and not pd.isna(row['Sector Weight']) and not pd.isna(row['True Sector Weight']):\n",
    "                    if isinstance(row['Sector Weight'], str) and isinstance(row['True Sector Weight'], str):\n",
    "                        if row['Sector Weight'].strip().lower() == row['True Sector Weight'].strip().lower():\n",
    "                            total_points_sector_weight_allocation += 1\n",
    "                    elif is_close(row['Sector Weight'], row['True Sector Weight']):\n",
    "                        total_points_sector_weight_allocation += 1\n",
    "                if 'Sector Performance' in row and 'True Performance' in row and not pd.isna(row['Sector Performance']) and not pd.isna(row['True Performance']) and isinstance(row['Sector Performance'], str) and row['Sector Performance'].strip().lower() == row['True Performance'].strip().lower():\n",
    "                    total_points_sector_performance_allocation += 1\n",
    "            elif effect_type == 'Selection':\n",
    "                # Increment maximum points counters for Selection\n",
    "                max_points_value_selection += 1\n",
    "                # Selection is always blank for Sector Weight\n",
    "                max_points_sector_weight_selection += 1\n",
    "                if 'Sector Performance' in row and 'True Performance' in row:\n",
    "                    max_points_sector_performance_selection += 1                \n",
    "                if not pd.isna(row['Value']) and not pd.isna(row['True Value']) and is_close(row['Value'], row['True Value']):\n",
    "                    total_points_value_selection += 1\n",
    "\n",
    "                # Check if 'Sector Weight' is blank (NaN) for Selection\n",
    "                #if pd.isna(row['Sector Weight']):\n",
    "                if df['Sector Weight'].empty:\n",
    "                    total_points_sector_weight_selection += 1\n",
    "                \n",
    "                if 'Sector Performance' in row and 'True Performance' in row and not pd.isna(row['Sector Performance']) and not pd.isna(row['True Performance']) and isinstance(row['Sector Performance'], str) and row['Sector Performance'].strip().lower() == row['True Performance'].strip().lower():\n",
    "                    total_points_sector_performance_selection += 1\n",
    "\n",
    "        # Append the summary of points for this file to the summary list\n",
    "        summary.append({\n",
    "            'File Name': filename,\n",
    "            'Prefix Type': prefix_type,\n",
    "            'Value Points Allocation': total_points_value_allocation,\n",
    "            'Value Ratio Allocation': total_points_value_allocation / max_points_value_allocation,\n",
    "            'Sector Weight Points Allocation': total_points_sector_weight_allocation,\n",
    "            'Sector Weight Ratio Allocation': total_points_sector_weight_allocation / max_points_sector_weight_allocation,\n",
    "            'Sector Performance Points Allocation': total_points_sector_performance_allocation,\n",
    "            'Sector Performance Ratio Allocation': total_points_sector_performance_allocation / max_points_sector_performance_allocation,\n",
    "            # Repeat for Selection\n",
    "            'Value Points Selection': total_points_value_selection,\n",
    "            'Value Ratio Selection': total_points_value_selection / max_points_value_selection,\n",
    "            'Sector Weight Points Selection': total_points_sector_weight_selection,\n",
    "            'Sector Weight Ratio Selection': total_points_sector_weight_selection / max_points_sector_weight_selection,\n",
    "\n",
    "            'Sector Performance Points Selection': total_points_sector_performance_selection,\n",
    "            'Sector Performance Ratio Selection': total_points_sector_performance_selection / max_points_sector_performance_selection\n",
    "        })\n",
    "\n",
    "# Convert the summary to a DataFrame and save it as a CSV file\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_csv_path = os.path.join(directory, 'summary_csv_points_by_effect_type_few_new.csv')\n",
    "summary_df.to_csv(summary_csv_path, index=False)\n",
    "\n",
    "#summary_csv_path = \"./Data/Attribution/Eval_Obj_1_csv/summary_csv_points.csv\"\n",
    "summary_df = pd.read_csv(summary_csv_path)\n",
    "\n",
    "# Function to extract fund type from filename\n",
    "def extract_fund_type(filename):\n",
    "    # Split the filename and extract the fund type\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        if part in ['Balanced', 'Growth', 'Defensive']:\n",
    "            return part\n",
    "    return \"Unknown\"  # Return 'Unknown' if fund type is not found\n",
    "\n",
    "# Apply the function to extract fund type and create a new column\n",
    "summary_df['Fund Type'] = summary_df['File Name'].apply(extract_fund_type)\n",
    "\n",
    "# Optionally, save the updated DataFrame back to a CSV file\n",
    "summary_df.to_csv(summary_csv_path, index=False)\n",
    "\n",
    "print(f\"Summary CSV saved at: {summary_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python311364bit7b1f43ad11604fee9b5b78de96b4c416"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
