{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04c0e1f5-6cd1-44ed-9a06-8c674ba46607",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import openai\n",
    "import pandas as pd\n",
    "OPENAI_API_KEY = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "model1 = 'gpt-3.5-turbo-16k'\n",
    "model2 = 'gpt-4-0613'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd2fdc55-4fe6-42d3-93ac-fae59a88e9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.7) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.agents import create_csv_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bd57ca54-8c55-484c-9ca0-021cb3aca9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Micro and Macro prompts\n",
    "\n",
    "# Load the data\n",
    "#input file\n",
    "question_file = 'Data/Attribution/attribution_by_gics_Obj_1.csv'\n",
    "answer_file = 'Data/Attribution/attribution_by_gics_Obj2_1.csv'\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate the prompt\n",
    "#def generate_prompt_micro(fund, period):\n",
    "\n",
    "generate_prompt_micro_2 = \"\"\"\n",
    "Calculate performance attribution using the Brinson Model for a specific Fund and Period with the provided data. Follow these formulas:\n",
    "- Allocation Effect = (Portfolio Weight - Benchmark Weight) * (Benchmark Return - Benchmark Total Return)\n",
    "- Selection Effect = Portfolio Weight * (Portfolio Return - Benchmark Return)\n",
    "- Total Contribution = Allocation Effect + Selection Effect\n",
    "- Benchmark Total Return = Weighted average of Benchmark weights and Benchmark returns\n",
    "\n",
    "This is a multi-level problem where sectors below to 'GICS Type'. \n",
    "\n",
    "Objective:\n",
    "1. Calculate 'Allocation Effect', 'Selection Effect', and 'Total Contribution' for all 'GICS Sector'. Output in CSV format, with the following columns: \n",
    "'GICS Sector', 'Allocation Effect', 'Selection Effect', 'Total Contribution', 'Fund', 'Period'. Each record should be on a new line.\n",
    "2. Calculate 'Allocation Effect', 'Selection Effect', and 'Total Contribution' for all 'GICS Type'. Output in CSV format, with the following columns: \n",
    "'GICS Type', 'Allocation Effect', 'Selection Effect', 'Total Contribution', 'Fund', 'Period'. Each record should be on a new line.\n",
    "3. Output should contain only the CSV format, initiated by 'CSV Format:'. No additional sentences, separators, wordings.\n",
    "\n",
    "Attention: Use pandas for calculations. Ensure accuracy and adherence to the formulas. \n",
    "Attention: Ensure the output contains only the CSV formatted data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "generate_prompt_macro = \"\"\"\n",
    "Your objective is to calculate performance attribution based on the Brinson Model for a specific Fund and Period with the provided data. Follow these formulas:\n",
    "'Allocation Effect' = (Portfolio Weight - Benchmark Weight) * (Benchmark Return - Benchmark Total Return)\n",
    "'Selection Effect' = Portfolio Weight * (Portfolio Return - Benchmark Return)\n",
    "'Total Contribution' = 'Allocation Effect' + 'Selection Effect'\n",
    "'Portfolio Contribution to Return' = Portfolio Weight * Portfolio Return\n",
    "'Benchmark Contribution to Return' = Benchmark Weight * Benchmark Return\n",
    "'Benchmark Total Return' is calculated as the weighted average between Benchmark weights and Benchmark returns.\n",
    "'Portfolio Return' is the sum over 'Portfolio Contribution to Return' divided by the specific level/segment total weight\n",
    "'Benchmark Return' is the sum over 'Benchmark Contribution to Return' divided by the specific level/segment total weight\n",
    "\n",
    "This is a multi-level problem where sectors belong to 'GICS Type'. Think carefully on how to aggregate before giving your answers.\n",
    "Your goal is to calculate Allocation and Selection effect for all 'GICS Type' from the top-down or highest segment, i.e at the 'GICS Type' level, following these steps:\n",
    "Step 1: Calculate 'Benchmark Total Return'\n",
    "Step 2: Calculate the 'Portfolio Return' and 'Benchmark Return' at each 'GICS Type' level.\n",
    "Step 3: Use these results to calculate the 'Allocation Effect', 'Selection Effect' at each 'GICS Type' level.\n",
    "Attention: Your output is in a CSV format with the following columns: GICS Type, Effect Type, Value, Fund, Period. Each record should be on a new line.\n",
    "Attention: 'Value' corresponds to the numerical values calculated in Step 3.\n",
    "Attention: Output should contain the CSV format, initiated by 'CSV Format:', but no additional sentences.\n",
    "Attention: Use pandas\n",
    "Attention: Be intentional, You are expected to provide numerical answers and perform calculations following the formulas and the steps provided.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "221cdf82-6dfd-4f63-8504-884b6b2f6afd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Calculate Benchmark Total Return\\nbenchmark_total_return = (df['Benchmark Weight'] * df['Benchmark Return']).sum()\\n\\n# Calculate Portfolio Return and Benchmark Return at each GICS Type level\\nportfolio_return = df.groupby('GICS Type')['Portfolio Weight', 'Portfolio Return'].apply(lambda x: (x['Portfolio Weight'] * x['Portfolio Return']).sum() / x['Portfolio Weight'].sum())\\nbenchmark_return = df.groupby('GICS Type')['Benchmark Weight', 'Benchmark Return'].apply(lambda x: (x['Benchmark Weight'] * x['Benchmark Return']).sum() / x['Benchmark Weight'].sum())\\n\\n# Calculate Allocation Effect and Selection Effect at each GICS Type level\\nallocation_effect = df.groupby('GICS Type').apply(lambda x: ((x['Portfolio Weight'] - x['Benchmark Weight']) * (benchmark_return - benchmark_total_return)).sum())\\nselection_effect = df.groupby('GICS Type').apply(lambda x: (x['Portfolio Weight'] * (portfolio_return - benchmark_return)).sum())\\n\\n# Create a dataframe for the results\\nresults = pd.DataFrame({'GICS Type': allocation_effect.index, 'Allocation Effect': allocation_effect.values, 'Selection Effect': selection_effect.values})\\nresults = results.melt(id_vars='GICS Type', var_name='Effect Type', value_name='Value')\\n\\n# Add Fund and Period columns\\nresults['Fund'] = df['Fund'].unique()[0]\\nresults['Period'] = df['Period'].unique()[0]\\n\\n# Convert the dataframe to CSV format\\ncsv_format = results.to_csv(index=False)\\n\\n# Print the CSV format\\nprint('CSV Format:')\\nprint(csv_format)\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mValueError: Cannot subset columns with a tuple with more than one element. Use a list instead.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Calculate Benchmark Total Return\\nbenchmark_total_return = (df['Benchmark Weight'] * df['Benchmark Return']).sum()\\n\\n# Calculate Portfolio Return and Benchmark Return at each GICS Type level\\nportfolio_return = df.groupby('GICS Type')[['Portfolio Weight', 'Portfolio Return']].apply(lambda x: (x['Portfolio Weight'] * x['Portfolio Return']).sum() / x['Portfolio Weight'].sum())\\nbenchmark_return = df.groupby('GICS Type')[['Benchmark Weight', 'Benchmark Return']].apply(lambda x: (x['Benchmark Weight'] * x['Benchmark Return']).sum() / x['Benchmark Weight'].sum())\\n\\n# Calculate Allocation Effect and Selection Effect at each GICS Type level\\nallocation_effect = df.groupby('GICS Type').apply(lambda x: ((x['Portfolio Weight'] - x['Benchmark Weight']) * (benchmark_return - benchmark_total_return)).sum())\\nselection_effect = df.groupby('GICS Type').apply(lambda x: (x['Portfolio Weight'] * (portfolio_return - benchmark_return)).sum())\\n\\n# Create a dataframe for the results\\nresults = pd.DataFrame({'GICS Type': allocation_effect.index, 'Allocation Effect': allocation_effect.values, 'Selection Effect': selection_effect.values})\\nresults = results.melt(id_vars='GICS Type', var_name='Effect Type', value_name='Value')\\n\\n# Add Fund and Period columns\\nresults['Fund'] = df['Fund'].unique()[0]\\nresults['Period'] = df['Period'].unique()[0]\\n\\n# Convert the dataframe to CSV format\\ncsv_format = results.to_csv(index=False)\\n\\n# Print the CSV format\\nprint('CSV Format:')\\nprint(csv_format)\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNameError: name 'benchmark_return' is not defined\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Calculate Benchmark Total Return\\nbenchmark_total_return = (df['Benchmark Weight'] * df['Benchmark Return']).sum()\\n\\n# Calculate Portfolio Return and Benchmark Return at each GICS Type level\\nportfolio_return = df.groupby('GICS Type')[['Portfolio Weight', 'Portfolio Return']].apply(lambda x: (x['Portfolio Weight'] * x['Portfolio Return']).sum() / x['Portfolio Weight'].sum())\\nbenchmark_return = df.groupby('GICS Type')[['Benchmark Weight', 'Benchmark Return']].apply(lambda x: (x['Benchmark Weight'] * x['Benchmark Return']).sum() / x['Benchmark Weight'].sum())\\n\\n# Calculate Allocation Effect and Selection Effect at each GICS Type level\\nallocation_effect = df.groupby('GICS Type').apply(lambda x: ((x['Portfolio Weight'] - x['Benchmark Weight']) * (benchmark_return.loc[x.name] - benchmark_total_return)).sum())\\nselection_effect = df.groupby('GICS Type').apply(lambda x: (x['Portfolio Weight'] * (portfolio_return.loc[x.name] - benchmark_return.loc[x.name])).sum())\\n\\n# Create a dataframe for the results\\nresults = pd.DataFrame({'GICS Type': allocation_effect.index, 'Allocation Effect': allocation_effect.values, 'Selection Effect': selection_effect.values})\\nresults = results.melt(id_vars='GICS Type', var_name='Effect Type', value_name='Value')\\n\\n# Add Fund and Period columns\\nresults['Fund'] = df['Fund'].unique()[0]\\nresults['Period'] = df['Period'].unique()[0]\\n\\n# Convert the dataframe to CSV format\\ncsv_format = results.to_csv(index=False)\\n\\n# Print the CSV format\\nprint('CSV Format:')\\nprint(csv_format)\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNameError: name 'benchmark_return' is not defined\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Calculate Benchmark Total Return\\nbenchmark_total_return = (df['Benchmark Weight'] * df['Benchmark Return']).sum()\\n\\n# Calculate Portfolio Return and Benchmark Return at each GICS Type level\\nportfolio_return = df.groupby('GICS Type')[['Portfolio Weight', 'Portfolio Return']].apply(lambda x: (x['Portfolio Weight'] * x['Portfolio Return']).sum() / x['Portfolio Weight'].sum())\\nbenchmark_return = df.groupby('GICS Type')[['Benchmark Weight', 'Benchmark Return']].apply(lambda x: (x['Benchmark Weight'] * x['Benchmark Return']).sum() / x['Benchmark Weight'].sum())\\n\\n# Calculate Allocation Effect and Selection Effect at each GICS Type level\\nallocation_effect = df.groupby('GICS Type').apply(lambda x: ((x['Portfolio Weight'] - x['Benchmark Weight']) * (benchmark_return[x.name] - benchmark_total_return)).sum())\\nselection_effect = df.groupby('GICS Type').apply(lambda x: (x['Portfolio Weight'] * (portfolio_return[x.name] - benchmark_return[x.name])).sum())\\n\\n# Create a dataframe for the results\\nresults = pd.DataFrame({'GICS Type': allocation_effect.index, 'Allocation Effect': allocation_effect.values, 'Selection Effect': selection_effect.values})\\nresults = results.melt(id_vars='GICS Type', var_name='Effect Type', value_name='Value')\\n\\n# Add Fund and Period columns\\nresults['Fund'] = df['Fund'].unique()[0]\\nresults['Period'] = df['Period'].unique()[0]\\n\\n# Convert the dataframe to CSV format\\ncsv_format = results.to_csv(index=False)\\n\\n# Print the CSV format\\nprint('CSV Format:')\\nprint(csv_format)\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNameError: name 'benchmark_return' is not defined\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Calculate Benchmark Total Return\\nbenchmark_total_return = (df['Benchmark Weight'] * df['Benchmark Return']).sum()\\n\\n# Calculate Portfolio Return and Benchmark Return at each GICS Type level\\nportfolio_return = df.groupby('GICS Type')[['Portfolio Weight', 'Portfolio Return']].apply(lambda x: (x['Portfolio Weight'] * x['Portfolio Return']).sum() / x['Portfolio Weight'].sum())\\nbenchmark_return = df.groupby('GICS Type')[['Benchmark Weight', 'Benchmark Return']].apply(lambda x: (x['Benchmark Weight'] * x['Benchmark Return']).sum() / x['Benchmark Weight'].sum())\\n\\n# Calculate Allocation Effect and Selection Effect at each GICS Type level\\nallocation_effect = df.groupby('GICS Type').apply(lambda x: ((x['Portfolio Weight'] - x['Benchmark Weight']) * (benchmark_return.loc[x.name] - benchmark_total_return)).sum())\\nselection_effect = df.groupby('GICS Type').apply(lambda x: (x['Portfolio Weight'] * (portfolio_return.loc[x.name] - benchmark_return.loc[x.name])).sum())\\n\\n# Create a dataframe for the results\\nresults = pd.DataFrame({'GICS Type': allocation_effect.index, 'Allocation Effect': allocation_effect.values, 'Selection Effect': selection_effect.values})\\nresults = results.melt(id_vars='GICS Type', var_name='Effect Type', value_name='Value')\\n\\n# Add Fund and Period columns\\nresults['Fund'] = df['Fund'].unique()[0]\\nresults['Period'] = df['Period'].unique()[0]\\n\\n# Convert the dataframe to CSV format\\ncsv_format = results.to_csv(index=False)\\n\\n# Print the CSV format\\nprint('CSV Format:')\\nprint(csv_format)\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNameError: name 'benchmark_return' is not defined\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"import pandas as pd\\n\\n# Calculate Benchmark Total Return\\nbenchmark_total_return = (df['Benchmark Weight'] * df['Benchmark Return']).sum()\\n\\n# Calculate Portfolio Return and Benchmark Return at each GICS Type level\\nportfolio_return = df.groupby('GICS Type')[['Portfolio Weight', 'Portfolio Return']].apply(lambda x: (x['Portfolio Weight'] * x['Portfolio Return']).sum() / x['Portfolio Weight'].sum())\\nbenchmark_return = df.groupby('GICS Type')[['Benchmark Weight', 'Benchmark Return']].apply(lambda x: (x['Benchmark Weight'] * x['Benchmark Return']).sum() / x['Benchmark Weight'].sum())\\n\\n# Calculate Allocation Effect and Selection Effect at each GICS Type level\\nallocation_effect = df.groupby('GICS Type').apply(lambda x: ((x['Portfolio Weight'] - x['Benchmark Weight']) * (benchmark_return.loc[x.name] - benchmark_total_return)).sum())\\nselection_effect = df.groupby('GICS Type').apply(lambda x: (x['Portfolio Weight'] * (portfolio_return.loc[x.name] - benchmark_return.loc[x.name])).sum())\\n\\n# Create a dataframe for the results\\nresults = pd.DataFrame({'GICS Type': allocation_effect.index, 'Allocation Effect': allocation_effect.values, 'Selection Effect': selection_effect.values})\\nresults = results.melt(id_vars='GICS Type', var_name='Effect Type', value_name='Value')\\n\\n# Add Fund and Period columns\\nresults['Fund'] = df['Fund'].unique()[0]\\nresults['Period'] = df['Period'].unique()[0]\\n\\n# Convert the dataframe to CSV format\\ncsv_format = results.to_csv(index=False)\\n\\n# Print the CSV format\\nprint('CSV Format:')\\nprint(csv_format)\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNameError: name 'benchmark_return' is not defined\u001b[0m"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 66\u001b[0m\n\u001b[1;32m     56\u001b[0m agent \u001b[38;5;241m=\u001b[39m create_csv_agent(\n\u001b[1;32m     57\u001b[0m     ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel2),\n\u001b[1;32m     58\u001b[0m     temp_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     memory\u001b[38;5;241m=\u001b[39mmemory_chat,\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Call the Agent\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m memory_chat\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Format the current time as a string, e.g., \"2023-10-23_15-30\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chains/base.py:507\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    508\u001b[0m         _output_key\n\u001b[1;32m    509\u001b[0m     ]\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    513\u001b[0m         _output_key\n\u001b[1;32m    514\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chains/base.py:312\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    313\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    314\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    315\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    316\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chains/base.py:306\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    299\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    300\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    301\u001b[0m     inputs,\n\u001b[1;32m    302\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    303\u001b[0m )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 306\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/agents/agent.py:1126\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1126\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1135\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1136\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/agents/agent.py:923\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    920\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/agents/openai_functions_agent/base.py:104\u001b[0m, in \u001b[0;36mOpenAIFunctionsAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, with_functions, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m messages \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_functions:\n\u001b[0;32m--> 104\u001b[0m     predicted_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     predicted_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mpredict_messages(\n\u001b[1;32m    111\u001b[0m         messages,\n\u001b[1;32m    112\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    113\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chat_models/base.py:662\u001b[0m, in \u001b[0;36mBaseChatModel.predict_messages\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     _stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(stop)\n\u001b[0;32m--> 662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chat_models/base.py:612\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    607\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    611\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 612\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chat_models/base.py:365\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    364\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 365\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    366\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    367\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    369\u001b[0m ]\n\u001b[1;32m    370\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chat_models/base.py:355\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 355\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m         )\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chat_models/base.py:507\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chat_models/openai.py:345\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    344\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chat_models/openai.py:284\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/langchain/chat_models/openai.py:282\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession_create_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#procedure for MACRO prompt\n",
    "\n",
    "import time\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "\n",
    "# Step 1: Read the input CSV file\n",
    "df = pd.read_csv('attribution_by_gics_Obj2_1.csv')\n",
    "\n",
    "\n",
    "# Function to save a CSV format DataFrame to a file\n",
    "def save_csv_temp(fund, period, data):\n",
    "    output_file = f\"temp_{fund}_{period.replace('/', '_')}.csv\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(data)\n",
    "    #print(f\"Results saved to {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "#step 2: save to csv function \n",
    "def save_results_to_csv_macro(fund, period, csv_data):\n",
    "    try:\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "        # Converting the CSV string to a DataFrame\n",
    "\n",
    "        df = pd.read_csv(StringIO(csv_data))\n",
    "        \n",
    "        # Adding Fund and Period columns\n",
    "        df['Fund'] = fund\n",
    "        df['Period'] = period\n",
    "        \n",
    "        # Reordering columns\n",
    "        df = df[['GICS Type', 'Effect Type', 'Effect Type Value', 'Fund', 'Period']]\n",
    "        \n",
    "        # Saving the DataFrame to a CSV file\n",
    "        output_file = f\"results_{fund}_{period.replace('/', '_')}_{timestamp}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Results saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save results to CSV for Fund: {fund}, Period: {period}. Error: {str(e)}\")\n",
    "   \n",
    "    \n",
    "# Step 3: Group by 'Fund' and 'Period'\n",
    "for (fund, period), group in df.groupby(['Fund', 'Period']):\n",
    "    # Step 3: Convert the group to a CSV format string \n",
    "    csv_data = group.to_csv(index=False)\n",
    "    temp_file = save_csv_temp(fund, period, csv_data)\n",
    "    \n",
    "    #Step 4: generate prompt\n",
    "    prompt = generate_prompt_macro\n",
    "\n",
    "    #Step 5: create and call agent\n",
    "    #agent setup\n",
    "    memory_chat = ConversationBufferMemory(memory_key=\"memory_chat\", return_messages=True)\n",
    "    agent = create_csv_agent(\n",
    "        ChatOpenAI(temperature=0, model=model2),\n",
    "        temp_file,\n",
    "        verbose=True,\n",
    "        agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "        memory=memory_chat,\n",
    "    )\n",
    "    \n",
    "    # Call the Agent\n",
    "    \n",
    "    response = agent.run(prompt)\n",
    "    memory_chat.clear()\n",
    "    # Format the current time as a string, e.g., \"2023-10-23_15-30\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    \n",
    "    #step 6: save to csv\n",
    "    #used for macro\n",
    "    try:\n",
    "        # Extracting the CSV-like part from the response text\n",
    "        csv_data = response.split(\"CSV Format:\\n\")[-1].strip()\n",
    "        #csv_data = response.split(\"GICS Type,Effect Type,Value\\n\")[-1].strip()\n",
    "        print(f\"Results for Fund: {fund}, Period: {period}\")\n",
    "        \n",
    "        # Save results to CSV\n",
    "        save_results_to_csv_macro(fund, period, csv_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse and save results for Fund: {fund}, Period: {period}. Error: {str(e)}\")\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c54fed73-2c3a-4023-9a95-931e34488254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed attribution_by_gics_Obj2_1.csv and saved the results to ./Results_BdMelo/macro_results.csv\n",
      "Processing file: results_Portfolio Defensive_10_1_2022 to 12_31_2022_2023-10-29_13-47.csv\n",
      "Processing file: results_Portfolio Defensive_1_31_2022 to 3_31_2022_2023-11-22_20-51.csv\n",
      "Processing file: results_Portfolio Defensive_4_1_2022 to 6_30_2022_2023-10-29_14-04.csv\n",
      "Processing file: results_Portfolio Defensive_7_1_2022 to 9_30_2022_2023-10-29_14-06.csv\n",
      "Processing file: results_Portfolio Growth_1_31_2022 to 3_31_2022_2023-10-29_14-07.csv\n",
      "Processing file: results_Portfolio Growth_4_1_2022 to 6_30_2022_2023-11-23_12-00.csv\n",
      "Processing file: results_Portfolio Growth_7_1_2022 to 9_30_2022_2023-10-29_14-32.csv\n",
      "Processing file: results_Portfolio Growth_10_1_2022 to 12_31_2022_2023-11-22_20-24.csv\n",
      "Processing file: results_Portfolio Value_1_31_2022 to 3_31_2022_2023-11-23_12-00.csv\n",
      "Processing file: results_Portfolio Value_7_1_2022 to 9_30_2022_2023-10-30_22-24.csv\n",
      "Processing file: results_Portfolio _VV_4_1_2022 to 6_30_2022_2023-10-30_22-03.csv\n",
      "Processing file: results_Portfolio _VV_10_1_2022 to 12_31_2022_2023-11-23_12-00.csv\n",
      "All comparison results saved to ./Results_BdMelo/all_comparison_results_11_23.csv.\n"
     ]
    }
   ],
   "source": [
    "# procedure to evaluate macro prompt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# List of file names to loop through\n",
    "\n",
    "file_names=['attribution_by_gics_Obj2_1.csv']\n",
    "\n",
    "# Replace with the directory where your CSV files are stored\n",
    "directory_path = './Results_BdMelo/'\n",
    "\n",
    "# Function to calculate weighted average\n",
    "def weighted_average(group, weight_col, return_col):\n",
    "    return (group[weight_col] * group[return_col]).sum() / group[weight_col].sum()\n",
    "\n",
    "# Loop through each CSV file in the directory\n",
    "for filename in file_names:\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        \n",
    "        # Step 1: Read the input CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Initialize a DataFrame to store results\n",
    "        results = []\n",
    "\n",
    "        # Step 2: Group by 'Fund', 'Period', and 'GICS Type'\n",
    "        grouped = df.groupby(['Fund', 'Period', 'GICS Type'])\n",
    "        for (fund, period, gics_type), group in grouped:\n",
    "            # Calculate weighted averages for the group\n",
    "            portfolio_weighted_avg = weighted_average(group, 'Portfolio Weight', 'Portfolio Return')\n",
    "            benchmark_weighted_avg = weighted_average(group, 'Benchmark Weight', 'Benchmark Return')\n",
    "\n",
    "            # Calculate the 'Benchmark Total Return' for the (Fund, Period) combination\n",
    "            benchmark_total_return = weighted_average(df[(df['Fund'] == fund) & (df['Period'] == period)], 'Benchmark Weight', 'Benchmark Return')\n",
    "\n",
    "            # Calculate 'Allocation Effect' and 'Selection Effect'\n",
    "            allocation_effect = (group['Portfolio Weight'].sum() - group['Benchmark Weight'].sum()) * (benchmark_weighted_avg - benchmark_total_return)\n",
    "            selection_effect = group['Portfolio Weight'].sum() * (portfolio_weighted_avg - benchmark_weighted_avg)\n",
    "\n",
    "            # Store the results for this GICS Type\n",
    "            results.append({\n",
    "                'Fund': fund,\n",
    "                'Period': period.replace('/', '_'),\n",
    "                'GICS Type': gics_type,\n",
    "                #'Portfolio Weighted Average': portfolio_weighted_avg,\n",
    "                #'Benchmark Weighted Average': benchmark_weighted_avg,\n",
    "                #'Benchmark Total Return': benchmark_total_return,\n",
    "                'Allocation Effect': allocation_effect,\n",
    "                'Selection Effect': selection_effect\n",
    "            })\n",
    "\n",
    "        # Convert results to DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Optionally, save the results to a CSV file\n",
    "        output_file_path = os.path.join(directory_path, f'macro_results.csv')\n",
    "        results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "        print(f'Processed {filename} and saved the results to {output_file_path}')\n",
    "\n",
    "#scoring procedure\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "file_ground_truth = './Results_BdMelo/macro_results.csv'\n",
    "\n",
    "# Read the ground truth file\n",
    "df_ground_truth = pd.read_csv(file_ground_truth)\n",
    "df_ground_truth['Period'] = df_ground_truth['Period'].str.replace('/', '_')\n",
    "\n",
    "# Define a similarity threshold for comparing the effects\n",
    "similarity_threshold = 1e-5  # This value can be adjusted as per requirements\n",
    "\n",
    "# Replace with the directory where your comparison CSV files are stored\n",
    "directory_path = './Results_BdMelo/'\n",
    "\n",
    "# List of file names to compare\n",
    "# Example: \n",
    "#'results_Portfolio Growth_7_1_2022 to 9_30_2022_2023-10-29_14-32.csv',\n",
    "file_names = [\n",
    "'results_Portfolio Defensive_10_1_2022 to 12_31_2022_2023-10-29_13-47.csv',\n",
    "'results_Portfolio Defensive_1_31_2022 to 3_31_2022_2023-11-22_20-51.csv',\n",
    "'results_Portfolio Defensive_4_1_2022 to 6_30_2022_2023-10-29_14-04.csv',\n",
    "'results_Portfolio Defensive_7_1_2022 to 9_30_2022_2023-10-29_14-06.csv',\n",
    "'results_Portfolio Growth_1_31_2022 to 3_31_2022_2023-10-29_14-07.csv',\n",
    "'results_Portfolio Growth_4_1_2022 to 6_30_2022_2023-11-23_12-00.csv',\n",
    "'results_Portfolio Growth_7_1_2022 to 9_30_2022_2023-10-29_14-32.csv',\n",
    "'results_Portfolio Growth_10_1_2022 to 12_31_2022_2023-11-22_20-24.csv',\n",
    "'results_Portfolio Value_1_31_2022 to 3_31_2022_2023-11-23_12-00.csv',\n",
    "'results_Portfolio Value_7_1_2022 to 9_30_2022_2023-10-30_22-24.csv',\n",
    "'results_Portfolio _VV_4_1_2022 to 6_30_2022_2023-10-30_22-03.csv',\n",
    "'results_Portfolio _VV_10_1_2022 to 12_31_2022_2023-11-23_12-00.csv'\n",
    "]\n",
    "\n",
    "comparison_results_list = []\n",
    "\n",
    "# Loop through each file name for comparison\n",
    "for file_name in file_names:\n",
    "    if file_name.endswith('.csv') and file_name != 'macro_results.csv':\n",
    "        # Read the comparison file\n",
    "        df_to_compare = pd.read_csv(os.path.join(directory_path, file_name))\n",
    "        df_to_compare['Period'] = df_to_compare['Period'].str.replace('/', '_')\n",
    "        print(f\"Processing file: {file_name}\")\n",
    "        # Pivot and rename columns to match df_ground_truth\n",
    "        df_to_compare_pivot = df_to_compare.pivot_table(\n",
    "            index=['Fund', 'Period', 'GICS Type'],\n",
    "            columns='Effect Type',\n",
    "            values='Value',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        #df_to_compare_pivot.columns.name = None  # Remove the categories name\n",
    "        df_to_compare_pivot.rename(columns={\n",
    "            'Allocation Effect': 'Allocation Effect_compare',\n",
    "            'Selection Effect': 'Selection Effect_compare'\n",
    "        }, inplace=True)\n",
    "\n",
    "        \n",
    "        #print(f\"Pivoted DataFrame has {df_to_compare_pivot.shape[0]} rows.\")\n",
    "\n",
    "        # Perform the comparison\n",
    "        comparison_df = pd.merge(\n",
    "            df_ground_truth,\n",
    "            df_to_compare_pivot,\n",
    "            on=['Fund', 'Period', 'GICS Type'],\n",
    "            how='inner',\n",
    "            suffixes=('_ground', '_compare')\n",
    "        )\n",
    "\n",
    "        # Calculate differences and scores\n",
    "        comparison_df['Allocation Effect Difference'] = comparison_df['Allocation Effect'] - comparison_df['Allocation Effect_compare']\n",
    "        comparison_df['Selection Effect Difference'] = comparison_df['Selection Effect'] - comparison_df['Selection Effect_compare']\n",
    "        comparison_df['Allocation Effect Score'] = (abs(comparison_df['Allocation Effect Difference']) <= similarity_threshold).astype(int)\n",
    "        comparison_df['Selection Effect Score'] = (abs(comparison_df['Selection Effect Difference']) <= similarity_threshold).astype(int)\n",
    "\n",
    "        # Add the file name as a column for reference\n",
    "        comparison_df['Compared File'] = file_name\n",
    "        \n",
    "        # Append to the list of results\n",
    "        comparison_results_list.append(comparison_df)\n",
    "\n",
    "# Concatenate all results into one DataFrame\n",
    "all_comparison_results = pd.concat(comparison_results_list)\n",
    "\n",
    "# Save the final results to a new CSV file\n",
    "output_file = './Results_BdMelo/all_comparison_results_11_23.csv'\n",
    "all_comparison_results.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"All comparison results saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7a79e5d6-d051-499a-a103-01f53904912b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Micro_results_Portfolio Growth_1_31_2022 to 3_31_2022_2023-10-31_12-25_part_1.csv\n",
      "Processing Micro_results_Portfolio Defensive_4_1_2022 to 6_30_2022_2023-10-31_12-19_part_1.csv\n",
      "Processing Micro_results_Portfolio VVV_1_31_2022 to 3_31_2022_2023-10-31_12-36_part_1.csv\n",
      "Processing Micro_results_Portfolio Defensive_10_1_2022 to 12_31_2022_2023-10-31_12-17_part_1.csv\n",
      "Processing Micro_results_Portfolio Defensive_7_1_2022 to 9_30_2022_2023-10-31_12-22_part_1.csv\n",
      "Processing Micro_results_Portfolio Growth_7_1_2022 to 9_30_2022_2023-10-31_12-33_part_1.csv\n",
      "Processing Micro_results_Portfolio VVV_4_1_2022 to 6_30_2022_2023-10-31_12-42_part_1.csv\n",
      "Processing Micro_results_Portfolio Defensive_1_31_2022 to 3_31_2022_2023-10-31_12-14_part_1.csv\n",
      "Processing Micro_results_Portfolio VVV_7_1_2022 to 9_30_2022_2023-10-31_12-44_part_1.csv\n",
      "Processing Micro_results_Portfolio Growth_4_1_2022 to 6_30_2022_2023-10-31_12-31_part_1.csv\n",
      "Processing Micro_results_Portfolio VVV_10_1_2022 to 12_31_2022_2023-10-31_12-39_part_1.csv\n",
      "Processing Micro_results_Portfolio Growth_10_1_2022 to 12_31_2022_2023-10-31_12-28_part_1.csv\n"
     ]
    }
   ],
   "source": [
    "# procedure to evaluate micro prompt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to ensure columns are numeric\n",
    "def to_numeric(column):\n",
    "    return pd.to_numeric(column, errors='coerce')\n",
    "\n",
    "# Define the directory path and file names\n",
    "directory_path = './Results_BdMelo/'\n",
    "\n",
    "# Define a tolerance for the score calculation\n",
    "tolerance = 1e-5  \n",
    "\n",
    "# Read the ground truth data\n",
    "df_attribution = pd.read_csv('attribution_by_gics_Obj_1.csv')\n",
    "\n",
    "# Ensure the 'Allocation Effect' column in df_attribution is numeric\n",
    "df_attribution['Allocation Effect'] = to_numeric(df_attribution['Allocation Effect'])\n",
    "df_attribution['Selection Effect'] = to_numeric(df_attribution['Selection Effect'])\n",
    "df_attribution['Total Contribution'] = to_numeric(df_attribution['Total Contribution'])\n",
    "\n",
    "# Define the GICS mapping\n",
    "# Create the mapping DataFrame\n",
    "gics_mapping = pd.DataFrame({\n",
    "    'GICS Sector': [\n",
    "        'Consumer Discret.', 'Financials', 'Materials', 'Real Estate', \n",
    "        'Consumer Staples', 'Health Care', 'Utilities', 'Cash',\n",
    "        'Communication', 'Energy', 'Industrials', 'IT'\n",
    "    ],\n",
    "    'GICS Type': [\n",
    "        'Cyclical', 'Cyclical', 'Cyclical', 'Cyclical',\n",
    "        'Defensive', 'Defensive', 'Defensive', 'Defensive',\n",
    "        'Sensitive', 'Sensitive', 'Sensitive', 'Sensitive'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Merge the mapping with df_attribution and aggregate by GICS Type\n",
    "df_attribution_mapped = df_attribution.merge(gics_mapping, on='GICS Sector')\n",
    "df_attribution_by_type = df_attribution_mapped.groupby(['GICS Type','Fund','Period']).sum().reset_index()\n",
    "\n",
    "# Function to calculate the score based on tolerance\n",
    "def calculate_score(value1, value2):\n",
    "    return int(abs(value1 - value2) <= tolerance)\n",
    "\n",
    "# Initialize a list to store scores for each file\n",
    "comparison_scores = []\n",
    "\n",
    "# Loop through each CSV file in the directory and process them\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.startswith('Micro_results') and file_name.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(directory_path, file_name))\n",
    "        \n",
    "        print(f'Processing {file_name}')\n",
    "\n",
    "        # Split the DataFrame into parts\n",
    "        # df_part1 contains the first 13 rows (1 header + 12 data rows)\n",
    "        df_part1 = df.iloc[:12]\n",
    "\n",
    "        # df_part2 starts from row 13, which contains the new header\n",
    "        # First, extract the data starting from the row 13 to the end\n",
    "        df_part2_data = df.iloc[12:]\n",
    "\n",
    "        # Now use the first row of this new DataFrame as the header for df_part2\n",
    "        new_header = df_part2_data.iloc[0]  # capture the header\n",
    "        df_part2 = df_part2_data[1:]  # take the data less the header row\n",
    "        df_part2.columns = new_header  # set the header row as the df header\n",
    "\n",
    "        # Reset index for both DataFrames if needed\n",
    "        df_part1.reset_index(drop=True, inplace=True)\n",
    "        df_part2.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Ensure the 'Allocation Effect' column in df_attribution is numeric\n",
    "        #df_part1['Allocation Effect'] = to_numeric(df_part1['Allocation Effect'])\n",
    "        #df_part1['Selection Effect'] = to_numeric(df_part1['Selection Effect'])\n",
    "        #df_part1['Total Contribution'] = to_numeric(df_part1['Total Contribution'])\n",
    "        df_part1.loc[:, 'Allocation Effect'] = pd.to_numeric(df_part1.loc[:, 'Allocation Effect'], errors='coerce')\n",
    "        df_part1.loc[:, 'Selection Effect'] = pd.to_numeric(df_part1.loc[:, 'Selection Effect'], errors='coerce')\n",
    "        df_part1.loc[:, 'Total Contribution'] = pd.to_numeric(df_part1.loc[:, 'Total Contribution'], errors='coerce')\n",
    "\n",
    "       # df_part2['Allocation Effect'] = to_numeric(df_part2['Allocation Effect'])\n",
    "       # df_part2['Selection Effect'] = to_numeric(df_part2['Selection Effect'])\n",
    "       # df_part2['Total Contribution'] = to_numeric(df_part2['Total Contribution'])\n",
    "        # Convert columns to numeric in df_part2, using .loc to avoid SettingWithCopyWarning\n",
    "        df_part2.loc[:, 'Allocation Effect'] = pd.to_numeric(df_part2.loc[:, 'Allocation Effect'], errors='coerce')\n",
    "        df_part2.loc[:, 'Selection Effect'] = pd.to_numeric(df_part2.loc[:, 'Selection Effect'], errors='coerce')\n",
    "        df_part2.loc[:, 'Total Contribution'] = pd.to_numeric(df_part2.loc[:, 'Total Contribution'], errors='coerce')\n",
    "\n",
    "        # Perform the comparison for part1\n",
    "        # Merge with the attribution data\n",
    "        merged_df = df_attribution.merge(df_part1, on=['Fund', 'Period', 'GICS Sector'])\n",
    "        \n",
    "        # Calculate scores\n",
    "        merged_df['Allocation Score'] = merged_df.apply(lambda row: calculate_score(row['Allocation Effect_x'], row['Allocation Effect_y']), axis=1)\n",
    "        merged_df['Selection Score'] = merged_df.apply(lambda row: calculate_score(row['Selection Effect_x'], row['Selection Effect_y']), axis=1)\n",
    "        merged_df['Total Contr Score'] = merged_df.apply(lambda row: calculate_score(row['Total Contribution_x'], row['Total Contribution_y']), axis=1)\n",
    "        # Compile the scores into the comparison_scores list\n",
    "        scores = {\n",
    "            'filename': file_name,\n",
    "            'Period': merged_df['Period'].iloc[0],\n",
    "            'Portfolio': merged_df['Fund'].iloc[0],  # Assuming Fund is the same for all rows\n",
    "            'Part1_Allocation Score': merged_df['Allocation Score'].sum(),\n",
    "            'Part1_Selection Score': merged_df['Selection Score'].sum(),\n",
    "            'Part1_Total Contr Score': merged_df['Total Contr Score'].sum()\n",
    "        }\n",
    "        comparison_scores.append(scores)        \n",
    "        \n",
    "        # Initialize score accumulators for part2\n",
    "        part2_allocation_scores = []\n",
    "        part2_selection_scores = []\n",
    "        part2_total_contr_scores = []\n",
    "        \n",
    "        # Iterate over df_part2 to calculate individual scores\n",
    "        for _, row in df_part2.iterrows():\n",
    "            # Find the corresponding row in df_attribution_by_type\n",
    "            attr_row = df_attribution_by_type[(df_attribution_by_type['Fund'] == row['Fund']) & \n",
    "                                              (df_attribution_by_type['Period'] == row['Period']) & \n",
    "                                              (df_attribution_by_type['GICS Type'] == row['GICS Type'])]\n",
    "\n",
    "            if not attr_row.empty:\n",
    "                # Calculate individual scores and add them to the lists\n",
    "                part2_allocation_scores.append(calculate_score(row['Allocation Effect'], attr_row['Allocation Effect'].iloc[0]))\n",
    "                part2_selection_scores.append(calculate_score(row['Selection Effect'], attr_row['Selection Effect'].iloc[0]))\n",
    "                part2_total_contr_scores.append(calculate_score(row['Total Contribution'], attr_row['Total Contribution'].iloc[0]))\n",
    "\n",
    "        # Sum the scores for all GICS Types\n",
    "        part2_allocation_score_sum = sum(part2_allocation_scores)\n",
    "        part2_selection_score_sum = sum(part2_selection_scores)\n",
    "        part2_total_contr_score_sum = sum(part2_total_contr_scores)\n",
    "        \n",
    "        # Find the index in combined_scores to update with part2 scores\n",
    "        score_index = next((index for (index, d) in enumerate(comparison_scores) if d['filename'] == file_name and d['Portfolio'] == row['Fund'] and d['Period'] == row['Period']), None)\n",
    "        if score_index is not None:\n",
    "            # Update the existing dictionary with Part2_ scores\n",
    "            comparison_scores[score_index].update({\n",
    "                'Part2_Allocation Score': part2_allocation_score_sum,\n",
    "                'Part2_Selection Score': part2_allocation_score_sum,\n",
    "                'Part2_Total Contr Score': part2_allocation_score_sum\n",
    "            })\n",
    "# Convert the combined scores list to a DataFrame\n",
    "final_scores_df = pd.DataFrame(comparison_scores)\n",
    "\n",
    "# Save the final scores DataFrame to a CSV file\n",
    "final_output_file = './Results_BdMelo/Micro_final_combined_scores.csv'\n",
    "final_scores_df.to_csv(final_output_file, index=False)\n",
    "\n",
    "# Return the path to the final output file\n",
    "#final_output_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "781dadf0-7293-4386-8934-501c6d31d777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Questions pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#input file\n",
    "question_file = 'attribution_by_gics_Obj_1.csv'\n",
    "answer_file = 'attribution_by_gics_Obj2_1.csv'\n",
    "\n",
    "\n",
    "# Sample data\n",
    "data = pd.read_csv(question_file)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# one type\n",
    "def generate_random_questions_1(df, num_questions=10, precision=5):\n",
    "    questions = []\n",
    "    #short_questions = []\n",
    "    columns = [\"Allocation Effect\", \"Selection Effect\", \"Total Contribution\"]\n",
    "    \n",
    "    for _ in range(num_questions):\n",
    "        # Randomly select a sector, a column, a fund, and a period\n",
    "        row = df.sample().iloc[0]\n",
    "        column_name = random.choice(columns)\n",
    "        fund = row['Fund']\n",
    "        period = row['Period']\n",
    "        #fund = random.choice(df['Fund'].unique())\n",
    "        #period = random.choice(df['Period'].unique())\n",
    "        \n",
    "        # Generate the question based on the selected sector and column\n",
    "        actual_value = row[column_name]\n",
    "        rounded_value = round(actual_value, precision)\n",
    "        \n",
    "        # Generate distractors from other rows in the DataFrame\n",
    "        distractors = set()\n",
    "        while len(distractors) < 3:\n",
    "            distractor_row = df.sample().iloc[0]\n",
    "            if distractor_row.name != row.name:\n",
    "                distractor_value = round(distractor_row[column_name], precision)\n",
    "                if distractor_value != rounded_value:\n",
    "                    distractors.add(distractor_value)\n",
    "        \n",
    "        options = [rounded_value] + list(distractors)\n",
    "        random.shuffle(options)\n",
    "        \n",
    "        question = {\n",
    "            \"question\": f\"The {column_name.replace('_', ' ').title()} from the {row['GICS Sector']} sector, in fund {fund}, in the period {period}, is:\",\n",
    "            \"options\": options,\n",
    "            \"correct_answer\": rounded_value\n",
    "            }\n",
    "        questions.append(question)\n",
    "            \n",
    "        #short_question = {            \n",
    "        #    \"question\": f\"Calculate the {column_name.replace('_', ' ').title()} from the {row['GICS Sector']} sector, in fund {fund}, in the period {period}:\",\n",
    "        #    \"correct_answer\": rounded_value    \n",
    "        #}\n",
    "        #short_questions.append(short_question)\n",
    "    \n",
    "    return questions\n",
    "\n",
    "import random\n",
    "\n",
    "#two types\n",
    "def generate_random_questions(df, num_questions=10, precision=5):\n",
    "    questions = []\n",
    "    columns = [\"Allocation Effect\", \"Selection Effect\", \"Total Contribution\"]\n",
    "    \n",
    "    for i in range(num_questions):\n",
    "        # Randomly select a sector, a column, and a question type\n",
    "        row = df.sample().iloc[0]\n",
    "        column_name = random.choice(columns)\n",
    "        fund = row['Fund']\n",
    "        period = row['Period']\n",
    "        \n",
    "        # Determine the question type based on the iteration\n",
    "        if i < num_questions // 2:\n",
    "            question_type = \"value\"\n",
    "            question_text = f\"The {column_name.replace('_', ' ').title()} from the {row['GICS Sector']} sector, in fund {fund}, in the period {period}, is closest to:\"\n",
    "        else:\n",
    "            question_type = \"calculation\"\n",
    "            question_text = f\"Calculate the {column_name.replace('_', ' ').title()} from the {row['GICS Sector']} sector, in fund {fund}, in the period {period}:\"\n",
    "        \n",
    "        # Generate the question based on the selected sector, column, and question type\n",
    "        actual_value = row[column_name]\n",
    "        rounded_value = round(actual_value, precision)\n",
    "        \n",
    "        # Generate distractors from other rows in the DataFrame\n",
    "        distractors = set()\n",
    "        while len(distractors) < 3:\n",
    "            distractor_row = df.sample().iloc[0]\n",
    "            if distractor_row.name != row.name and distractor_row['Fund'] == fund and distractor_row['Period'] == period:\n",
    "                distractor_value = round(distractor_row[column_name], precision)\n",
    "                if distractor_value != rounded_value:\n",
    "                    distractors.add(distractor_value)\n",
    "        \n",
    "        options = [rounded_value] + list(distractors)\n",
    "        random.shuffle(options)\n",
    "        \n",
    "        question = {\n",
    "            \"question\": question_text,\n",
    "            \"options\": options,\n",
    "            \"correct_answer\": rounded_value,\n",
    "            \"question_type\": question_type\n",
    "        }\n",
    "        questions.append(question)\n",
    "        \n",
    "    return questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1630d1cb-5987-469f-b23c-812817fea26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# formating question into the prompt\n",
    "# creating agent\n",
    "# running llm\n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "#one type\n",
    "def format_question_1(question):\n",
    "    choices = \"\\n\".join([f\"{letter}: {option}%\" for letter, option in zip(\"ABCD\", question['options'])])\n",
    "    prompt = f\"\"\"\n",
    "    Question below is about performance attribution, use instructions to find a solution and follow these guidelines:\n",
    "    Guidelines:\n",
    "    -You are giving four choices to answer the question. You must choose one of the answers and your output is just the first letter of that answer, nothing else. \n",
    "    -Answer 'E' if you do not know the answer.\n",
    "    -Before giving final answer, recall relevant problems and solutions.\n",
    "    Instructions:\n",
    "    *'Allocation Effect' = (Portfolio Weight - Benchmark Weight) * (Benchmark Return - Benchmark Total Return)\n",
    "    *'Selection Effect' = Portfolio Weight * (Portfolio Return - Benchmark Return)\n",
    "    *'Total Contribution' = 'Allocation Effect' + 'Selection Effect'\n",
    "    *'Benchmark Total Return' is calculated as the weighted average between Benchmark weights and Benchmark returns\n",
    "    Question:\n",
    "    Using the Brinson Model, {question['question']}\n",
    "    Choices:\n",
    "    {choices}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "#two types\n",
    "#prompt type 1\n",
    "def format_question_2(question):\n",
    "    \"\"\"Formats the question for GPT-4.\"\"\"\n",
    "    options_text = \"\\n\".join([f\"{letter}: {opt}%\" for letter, opt in zip(\"ABCD\", question['options'])])\n",
    "    \n",
    "    if \"is closest to\" in question[\"question\"]:\n",
    "        # It's a \"value\" question\n",
    "        prompt = f\"\"\"\n",
    "        Question below asks you to calculate performance attribution based on the Brinson Model.\n",
    "\n",
    "        You know that for a specific Fund and Period:\n",
    "        'Allocation Effect' = (Portfolio Weight - Benchmark Weight) * (Benchmark Return - Benchmark Total Return)\n",
    "        'Selection Effect' = Portfolio Weight * (Portfolio Return - Benchmark Return)\n",
    "        'Total Contribution' = 'Allocation Effect' + 'Selection Effect'\n",
    "        'Benchmark Total Return' is calculated as the weighted average between columns 'Benchmark weight' and 'Benchmark return'\n",
    "        \n",
    "        You are giving four choices to answer the question. You must choose one of the answers and your output is just the first letter of that answer, nothing else.\n",
    "        Answer 'E' if you do not know the answer.\n",
    "        Attention: Data provided contains various funds and periods. Choose correctly.\n",
    "        Question:\n",
    "        Solve step-by-step, first extract the Fund and Period provided in the question, second calculate 'Benchmark Total Return' for all 'GICS Sector' filtered by the Fund and Period extracted, \n",
    "        third calculate Allocation and Selection Effect for all 'GICS Sector' filtered by the Fund and Period extracted; and finally answer the following: {question[\"question\"]}\n",
    "        Choices:\n",
    "        {options_text}\n",
    "        Answer:\"\"\"\n",
    "    else:\n",
    "        # It's a \"calculation\" question\n",
    "        prompt = f\"\"\"\n",
    "        Question below asks you to calculate performance attribution based on the Brinson Model. Make sure to output the answer as a numerical value rounded to five decimal places.\n",
    "        \n",
    "        You know that for a specific Fund and Period:\n",
    "        'Allocation Effect' = (Portfolio Weight - Benchmark Weight) * (Benchmark Return - Benchmark Total Return)\n",
    "        'Selection Effect' = Portfolio Weight * (Portfolio Return - Benchmark Return)\n",
    "        'Total Contribution' = 'Allocation Effect' + 'Selection Effect'\n",
    "        'Benchmark Total Return' is calculated as the weighted average between columns 'Benchmark weight' and 'Benchmark return'\n",
    "        \n",
    "        Note: Your answer should be a single numerical value rounded to five decimal places.\n",
    "        Attention: Data provided contains various funds and periods. Choose correctly.\n",
    "        Question:\n",
    "        Solve step-by-step, first extract the Fund and Period provided in the question, second calculate 'Benchmark Total Return' for all 'GICS Sector' filtered by the Fund and Period extracted, \n",
    "        third calculate Allocation and Selection Effect for all 'GICS Sector' filtered by the Fund and Period extracted; and finally answer the following: {question[\"question\"]}\n",
    "        Note: Your answer should be a single numerical value rounded to five decimal places, nothing else.\n",
    "        Answer:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "#prompt type 2\n",
    "def format_question_3(question):\n",
    "    \"\"\"Formats the question for GPT-4.\"\"\"\n",
    "    options_text = \"\\n\".join([f\"{letter}: {opt}%\" for letter, opt in zip(\"ABCD\", question['options'])])\n",
    "    \n",
    "    if \"is closest to\" in question[\"question\"]:\n",
    "        # It's a \"value\" question\n",
    "        prompt = f\"\"\"\n",
    "        Question below is about performance attribution, use instructions to find a solution based on provided data and follow these guidelines:\n",
    "        Guidelines:\n",
    "        -You are giving four choices to answer the question. You must choose one of the answers and your output is just the first letter of that answer, nothing else. \n",
    "        -Answer 'E' if you do not know the answer.\n",
    "        \n",
    "        Instructions:\n",
    "        *'Allocation Effect' = (Portfolio Weight - Benchmark Weight) * (Benchmark Return - Benchmark Total Return)\n",
    "        *'Selection Effect' = Portfolio Weight * (Portfolio Return - Benchmark Return)\n",
    "        *'Total Contribution' = 'Allocation Effect' + 'Selection Effect'\n",
    "        *'Benchmark Total Return' is calculated as the weighted average between columns 'Benchmark weight' and 'Benchmark return'\n",
    "        Question:\n",
    "        Using the Brinson Model, {question['question']}\n",
    "        Choices:\n",
    "        {options_text}\n",
    "        Answer:\"\"\"\n",
    "    else:\n",
    "        # It's a \"calculation\" question\n",
    "        prompt = f\"\"\"\n",
    "        In the context of performance attribution analysis using the Brinson Model, calculate the numerical value based on the provided information and instructions. Make sure to output the answer as a numerical value rounded to five decimal places.\n",
    "        Do not include any additional text or characters in your answer.\n",
    "        Instructions:\n",
    "        - 'Allocation Effect' is calculated as (Portfolio Weight - Benchmark Weight) * (Benchmark Return - Benchmark Total Return).\n",
    "        - 'Selection Effect' is calculated as Portfolio Weight * (Portfolio Return - Benchmark Return).\n",
    "        - 'Total Contribution' is the sum of 'Allocation Effect' and 'Selection Effect'.\n",
    "        - 'Benchmark Total Return' is calculated as the weighted average between columns 'Benchmark weight' and 'Benchmark return'\n",
    "        \n",
    "        Example:\n",
    "        If the Portfolio Weight is 0.1, Benchmark Weight is 0.4, Portfolio Return is 0.05, Benchmark Return is 0.2, and Benchmark Total Return is 0.126, then:\n",
    "        - Allocation Effect = (0.1 - 0.4) * (0.2 - 0.126) = -0.0222\n",
    "        - Selection Effect = 0.1 * (0.05 - 0.2) = -0.015\n",
    "        - Total Contribution = -0.0222 - 0.015 = -0.0372\n",
    "        Example for 'Benchmark Total Return':\n",
    "        Suppose you have the following data:\n",
    "        Benchmark Weight: [0.2, 0.4, 0.4]\n",
    "        Benchmark Return: [0.15, 0.2, 0.04]\n",
    "        Benchmark Total Return = [(0.2 * 0.15) + (0.4 * 0.2) + (0.4 * 0.04)] / (0.2 + 0.4 + 04) = 0.126\n",
    "\n",
    "        Note: Your answer should be a single numerical value rounded to five decimal places.\n",
    "\n",
    "        Question: \n",
    "        {question[\"question\"]}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    return prompt\n",
    "#-Before giving final answer, recall relevant problems and solutions.\n",
    "\n",
    "def ask_gpt_openai(question, temperature):\n",
    "    formatted_question = format_question_2({\"question\": question[\"question\"], \"options\": question[\"options\"]})\n",
    "    \n",
    "    #agent setup\n",
    "    agent = create_csv_agent(\n",
    "        ChatOpenAI(temperature=temperature, model=model2),\n",
    "        answer_file,\n",
    "        verbose=False,\n",
    "        agent_type=AgentType.OPENAI_FUNCTIONS\n",
    "    ) \n",
    "    memory_chat = ConversationBufferMemory()\n",
    "    response = agent.run(formatted_question)\n",
    "    memory_chat.clear()\n",
    "    return response\n",
    "\n",
    "def ask_gpt_openai_token(question, temperature):\n",
    "    formatted_question = format_question_2({\"question\": question[\"question\"], \"options\": question[\"options\"]})\n",
    "    with get_openai_callback() as cb:\n",
    "        #agent setup\n",
    "        agent = create_csv_agent(\n",
    "            ChatOpenAI(temperature=temperature, model=model2),\n",
    "            answer_file,\n",
    "            verbose=False,\n",
    "            agent_type=AgentType.OPENAI_FUNCTIONS\n",
    "        ) \n",
    "        memory_chat = ConversationBufferMemory()\n",
    "        response = agent.run(formatted_question)\n",
    "        total_tk = cb.total_tokens\n",
    "        tk_prompt = cb.prompt_tokens\n",
    "        tk_completion = cb.completion_tokens\n",
    "        total_cost = cb.total_cost\n",
    "        memory_chat.clear()\n",
    "    return response, total_tk, tk_prompt, tk_completion, total_cost\n",
    "\n",
    "# Generate 50 random questions\n",
    "questions = generate_random_questions(df, num_questions=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce262f0-7d0e-4db3-950b-402fb23cb060",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'gpt4_results_2023-11-22_12-38.csv'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Temperatures to loop over\n",
    "temperatures = [0]\n",
    "\n",
    "# agent types\n",
    "#ag_types = ['AgentType.OPENAI_FUNCTIONS','AgentType.ZERO_SHOT_REACT_DESCRIPTION']\n",
    "\n",
    "# Prepare data for CSV\n",
    "csv_data = []\n",
    "\n",
    "#QA\n",
    "\n",
    "for temperature in temperatures:\n",
    "    # Ask GPT-4 the questions one by one and compile the answers\n",
    "    gpt_responses = [ask_gpt_openai(question, temperature) for question in questions]\n",
    "   \n",
    "        # Check if the answer is correct\n",
    "        #is_correct = is_answer_correct(question, gpt_response)\n",
    "\n",
    "    # Store results in CSV data\n",
    "    for i, (question, gpt_response) in enumerate(zip(questions, gpt_responses), start=1):\n",
    "        correct_option = \"ABCD\"[question['options'].index(question['correct_answer'])]\n",
    "        correct_value = question['correct_answer']\n",
    "\n",
    "        question_type = question['question_type']\n",
    "\n",
    "        question_prompt = question['question']\n",
    "\n",
    "        if question_type == \"value\":\n",
    "            correct_option = \"ABCD\"[question['options'].index(question['correct_answer'])]\n",
    "            is_correct = 1 if correct_option == gpt_response else 0\n",
    "        elif question_type == \"calculation\":\n",
    "            try:\n",
    "                gpt_response_number = round(float(gpt_response.strip()), 5)\n",
    "            except ValueError:\n",
    "                gpt_response_number = None\n",
    "            is_correct = 1 if gpt_response_number == question['correct_answer'] else 0\n",
    "\n",
    "\n",
    "        csv_data.append({\n",
    "            \"Question Number\": i,\n",
    "            \"Question Type\": question_type,\n",
    "            \"Question\": question_prompt,\n",
    "            \"LLM Answer\": gpt_response,\n",
    "            \"Correct Choice\": correct_option,\n",
    "            \"Correct Value\": correct_value,\n",
    "            \"Is Correct\": is_correct,\n",
    "            \"Temperature\": temperature,\n",
    "            \"Agent Type\": \"OpenAI_Functions\",\n",
    "            \"Model Type\": \"GPT-4\"\n",
    "\n",
    "        })\n",
    "\n",
    "        \n",
    "# Format the current time as a string, e.g., \"2023-10-23_15-30\"\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "   \n",
    "# Write results to CSV\n",
    "filename = f'gpt4_results_{timestamp}.csv'\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = [\"Question Number\", \"Question Type\", \"Question\", \"LLM Answer\", \"Correct Choice\", \"Correct Value\", \"Is Correct\", \"Temperature\", \"Agent Type\", \"Model Type\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    writer.writerows(csv_data)\n",
    "\n",
    "print(f\"Results saved to '{filename}'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d546443-333f-4f27-9591-2bc29c5522b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Question Type  Correct_Sum  Total_Questions  Correct_Ratio\n",
      "0   calculation           59               70       0.842857\n",
      "1         value           62               70       0.885714\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory where the files are located\n",
    "directory = \"./Results_BdMelo\"  # Replace with your folder path\n",
    "\n",
    "# List of filenames\n",
    "file_names = [\n",
    "\"gpt4_results_2023-10-28_13-53.csv\",\n",
    "\"gpt4_results_2023-10-28_14-06.csv\",\n",
    "\"gpt4_results_2023-10-28_17-48.csv\",\n",
    "\"gpt4_results_2023-10-28_17-53.csv\",\n",
    "\"gpt4_results_2023-10-28_17-57.csv\",\n",
    "\"gpt4_results_2023-10-28_18-01.csv\",\n",
    "\"gpt4_results_2023-10-28_19-05.csv\",\n",
    "\"gpt4_results_2023-11-13_00-19.csv\",\n",
    "\"gpt4_results_2023-11-13_00-24.csv\",\n",
    "\"gpt4_results_2023-11-13_00-27.csv\",\n",
    "\"gpt4_results_2023-11-13_00-33.csv\",\n",
    "\"gpt4_results_2023-11-13_00-43.csv\",\n",
    "\"gpt4_results_2023-11-22_12-38.csv\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# Concatenate all dataframes\n",
    "all_dfs = []\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['FileName'] = file_name\n",
    "        all_dfs.append(df)\n",
    "        \n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame before grouping\n",
    "combined_df.to_csv(\"./Results_BdMelo/combined_output.csv\", index=False)\n",
    "\n",
    "# Group by 'Question Type' and aggregate\n",
    "grouped = combined_df.groupby('Question Type').agg(\n",
    "    Correct_Sum=('Is Correct', 'sum'),\n",
    "    Total_Questions=('Is Correct', 'count')\n",
    ")\n",
    "\n",
    "# Calculate the ratio of correct answers\n",
    "grouped['Correct_Ratio'] = grouped['Correct_Sum'] / grouped['Total_Questions']\n",
    "\n",
    "# Reset index for better readability\n",
    "grouped_reset = grouped.reset_index()\n",
    "\n",
    "# Display or save the grouped DataFrame\n",
    "print(grouped_reset)\n",
    "grouped_reset.to_csv(\"./Results_BdMelo/output_grouped_file.csv\", index=False)  # Save to CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4095b39-edcb-4ff9-9f47-be4f5165ccc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# token cost implementation\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Temperatures to loop over\n",
    "temperatures = [0]\n",
    "\n",
    "# agent types\n",
    "#ag_types = ['AgentType.OPENAI_FUNCTIONS','AgentType.ZERO_SHOT_REACT_DESCRIPTION']\n",
    "\n",
    "# Prepare data for CSV\n",
    "csv_data = []\n",
    "\n",
    "#QA\n",
    "\n",
    "for temperature in temperatures:\n",
    "    # Ask GPT-4 the questions one by one and compile the answers\n",
    "    #gpt_responses = [ask_gpt_openai(question, temperature) for question in questions]\n",
    "    \n",
    "    # Initialize lists to store the results\n",
    "    gpt_responses = []\n",
    "    total_token = []\n",
    "    token_prompt = []\n",
    "    token_completion = []\n",
    "    total_cost_usd = []\n",
    "\n",
    "    # Ask GPT-4 the questions one by one and compile the answers\n",
    "    #gpt_responses = [ask_gpt_openai(question, temperature) for question in questions]\n",
    "    for question in questions:\n",
    "        response, total_tk, tk_prompt, tk_completion, total_cost = ask_gpt_openai_token(question, temperature)\n",
    "        gpt_responses.append(response)\n",
    "        total_token.append(total_tk)\n",
    "        token_prompt.append(tk_prompt)\n",
    "        token_completion.append(tk_completion)\n",
    "        total_cost_usd.append(total_cost)\n",
    "    \n",
    "    \n",
    "        # Check if the answer is correct\n",
    "        #is_correct = is_answer_correct(question, gpt_response)\n",
    "\n",
    "    # Store results in CSV data\n",
    "    for i, (question, gpt_response) in enumerate(zip(questions, gpt_responses), start=1):\n",
    "        correct_option = \"ABCD\"[question['options'].index(question['correct_answer'])]\n",
    "        correct_value = question['correct_answer']\n",
    "\n",
    "        question_type = question['question_type']\n",
    "\n",
    "        question_prompt = question['question']\n",
    "\n",
    "        if question_type == \"value\":\n",
    "            correct_option = \"ABCD\"[question['options'].index(question['correct_answer'])]\n",
    "            is_correct = 1 if correct_option == gpt_response else 0\n",
    "        elif question_type == \"calculation\":\n",
    "            try:\n",
    "                gpt_response_number = round(float(gpt_response.strip()), 5)\n",
    "            except ValueError:\n",
    "                gpt_response_number = None\n",
    "            is_correct = 1 if gpt_response_number == question['correct_answer'] else 0\n",
    "\n",
    "\n",
    "        csv_data.append({\n",
    "            \"Question Number\": i,\n",
    "            \"Question Type\": question_type,\n",
    "            \"Question\": question_prompt,\n",
    "            \"LLM Answer\": gpt_response,\n",
    "            \"Correct Choice\": correct_option,\n",
    "            \"Correct Value\": correct_value,\n",
    "            \"Is Correct\": is_correct,\n",
    "            \"Temperature\": temperature,\n",
    "            \"Agent Type\": \"OpenAI_Functions\",\n",
    "            \"Model Type\": \"GPT-4\"\n",
    "\n",
    "        })\n",
    "\n",
    "    data_cost = {\n",
    "        \"Total Token\": total_token,\n",
    "        \"Prompt Tokens\": token_prompt,\n",
    "        \"Complete Tokens\": token_completion,\n",
    "        \"Total Cost (USD)\": total_cost_usd\n",
    "    }\n",
    "    df_cost = pd.DataFrame(data_cost)        \n",
    "        \n",
    "        \n",
    "# Format the current time as a string, e.g., \"2023-10-23_15-30\"\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "#cost file\n",
    "filename_cost = f\"cost_{timestamp}.csv\"\n",
    "df_cost.to_csv(filename_cost, index=False)\n",
    "print(f\"Cost saved to '{filename}'\")\n",
    "    \n",
    "    \n",
    "# Write results to CSV\n",
    "filename = f'gpt4_results_{timestamp}.csv'\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = [\"Question Number\", \"Question Type\", \"Question\", \"LLM Answer\", \"Correct Choice\", \"Correct Value\", \"Is Correct\", \"Temperature\", \"Agent Type\", \"Model Type\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    writer.writerows(csv_data)\n",
    "\n",
    "print(f\"Results saved to '{filename}'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d182bfa-b3d0-444c-a07e-64fbff463d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python311364bit7b1f43ad11604fee9b5b78de96b4c416"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
